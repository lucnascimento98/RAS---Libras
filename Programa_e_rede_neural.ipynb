{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Programa_e_rede_neural.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1LNorj-DLNHSOhM9wbM-l2CflqoafN8uB","authorship_tag":"ABX9TyOeIxYJSbc03KBlacJXHqOI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZcxIHB2fF9J6"},"source":["import numpy as np\n","import os\n","import cv2\n","\n","DATADIR = \"/content/drive/Shared drives/RAS - LIBRAS/RAS---Libras/dataset/training\" # Onde estão sendo armazenados os arquivos\n","CATEGORIES = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"I\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"Y\"] # Possibilidades de estudo\n","\n","training_data = []\n","IMG_SIZE = 64 # Definindo o tamanho da imagem\n","\n","def create_training_data():\n","    for category in CATEGORIES:\n","        path = os.path.join(DATADIR,category) # Caminho com os diretórios das letras\n","        class_num = CATEGORIES.index(category) # Dando um número para a categoria\n","        for img in os.listdir(path):\n","            try:\n","                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE) #Cada imagem também é convertida na escala de cinza\n","                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) # Redimensionando a imagem\n","                training_data.append([new_array,class_num]) # Inserindo a imagem e sua classificação\n","                print(category,img)\n","            except Exception as e: # Erro que pode ocorrer ao importar imagens\n","                pass\n","\n","create_training_data()\n","\n","import random\n","random.shuffle(training_data) # Embaralhando os dados que a rede vai usar para treinar\n","\n","X = [] # Features\n","y = [] # Labels\n","\n","for features, label in training_data:\n","    X.append(features)\n","    y.append(label)\n","\n","X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1) # -1: Quantas features tem, IMG_SIZE x IMG_SIZE: tamanho da imagem, 1: indica que o canal de cores é só o cinza (3 se RGB)\n","\n","import pickle # Salvar os arquivos criados \n","\n","pickle_out = open(\"/content/drive/Shared drives/RAS - LIBRAS/RAS---Libras/output/X_all.pickle\",\"wb\") # Salvar X\n","pickle.dump(X,pickle_out)\n","pickle_out.close()\n","\n","pickle_out = open(\"/content/drive/Shared drives/RAS - LIBRAS/RAS---Libras/output/y_all.pickle\",\"wb\") # Salvar y\n","pickle.dump(y,pickle_out)\n","pickle_out.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnqrzmbBoocC","executionInfo":{"status":"ok","timestamp":1604194673329,"user_tz":180,"elapsed":227338,"user":{"displayName":"Lucas Serrano Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJg9VGUScSUQ5E1TF8bjynSe573dEKl8JptKBS3Q=s64","userId":"04398573326298672912"}},"outputId":"6b392a7d-67bc-4579-f44d-1400a77478ab","colab":{"base_uri":"https://localhost:8080/"}},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential # Modelo Sequencial\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.callbacks import TensorBoard # Para visualização do Modelo da Rede Neural\n","import pickle\n","import numpy as np\n","\n","import time\n","\n","NAME = 'Verificação_de_letras-cnn-64x2-{}'.format(int(time.time()))\n","\n","tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME)) # Para ter uma visualização do treinamento da rede neural\n","\n","pickle_in = open(\"/content/drive/Shared drives/RAS - LIBRAS/RAS---Libras/output/X_all.pickle\",\"rb\")\n","X = np.array(pickle.load(pickle_in))\n","\n","pickle_in = open(\"/content/drive/Shared drives/RAS - LIBRAS/RAS---Libras/output/y_all.pickle\",\"rb\")\n","y = np.array(pickle.load(pickle_in))\n","\n","X = np.array(X/255.0) # Simplificando coloração de Pixels para valores entre 0 e 1\n","\n","model = Sequential([Conv2D(64,(2,2), activation='relu', input_shape = X.shape[1:]), # Primeira camada\n","                    MaxPooling2D(pool_size=(2,2)),\n","\n","                    Conv2D(128,(2,2), activation='relu'), # Segunda camada\n","                    MaxPooling2D(pool_size=(2,2)),\n","\n","                    Conv2D(256,(2,2), activation='relu'), # Terceira camada\n","                    MaxPooling2D(pool_size=(2,2)),\n","\n","                    Conv2D(256,(2,2), activation='relu'), # Quarta camada\n","                    MaxPooling2D(pool_size=(2,2)),\n","\n","                    Flatten(),\n","                    Dropout(.75), # Faz a rede neural não usar todos os neuronios durante o treinamento\n","                    Dense(512, activation='relu'), # Quinta camada\n","\n","                    Dense(22, activation='softmax')]) # Camada de Saída\n","\n","# model.summary()\n","adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model.compile(optimizer= adam, loss='SparseCategoricalCrossentropy', metrics=['acc'])\n","model.fit(X, y, batch_size=32, epochs=25, validation_split=0.1, callbacks = [tensorboard])\n","\n","model.save('/content/drive/Shared drives/RAS - LIBRAS/RAS---Libras/output/treinando_rede_all.model') # Salvando Rede Neural"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","  2/930 [..............................] - ETA: 39s - loss: 3.0916 - acc: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0093s vs `on_train_batch_end` time: 0.0689s). Check your callbacks.\n","930/930 [==============================] - 9s 10ms/step - loss: 0.9951 - acc: 0.6796 - val_loss: 0.0833 - val_acc: 0.9755\n","Epoch 2/25\n","930/930 [==============================] - 9s 9ms/step - loss: 0.1554 - acc: 0.9451 - val_loss: 0.0415 - val_acc: 0.9879\n","Epoch 3/25\n","930/930 [==============================] - 9s 9ms/step - loss: 0.0892 - acc: 0.9690 - val_loss: 0.0135 - val_acc: 0.9967\n","Epoch 4/25\n","930/930 [==============================] - 9s 9ms/step - loss: 0.0673 - acc: 0.9770 - val_loss: 0.0080 - val_acc: 0.9982\n","Epoch 5/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0544 - acc: 0.9822 - val_loss: 0.0089 - val_acc: 0.9973\n","Epoch 6/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0476 - acc: 0.9838 - val_loss: 0.0065 - val_acc: 0.9979\n","Epoch 7/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0413 - acc: 0.9870 - val_loss: 0.0039 - val_acc: 0.9985\n","Epoch 8/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0396 - acc: 0.9873 - val_loss: 0.0050 - val_acc: 0.9982\n","Epoch 9/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0314 - acc: 0.9901 - val_loss: 0.0028 - val_acc: 0.9988\n","Epoch 10/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0372 - acc: 0.9890 - val_loss: 0.0027 - val_acc: 0.9991\n","Epoch 11/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0270 - acc: 0.9915 - val_loss: 0.0025 - val_acc: 0.9991\n","Epoch 12/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0262 - acc: 0.9924 - val_loss: 0.0041 - val_acc: 0.9991\n","Epoch 13/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0297 - acc: 0.9908 - val_loss: 0.0028 - val_acc: 0.9991\n","Epoch 14/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0234 - acc: 0.9931 - val_loss: 0.0019 - val_acc: 0.9991\n","Epoch 15/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0058 - val_acc: 0.9982\n","Epoch 16/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0204 - acc: 0.9935 - val_loss: 0.0051 - val_acc: 0.9985\n","Epoch 17/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0216 - acc: 0.9931 - val_loss: 0.0021 - val_acc: 0.9994\n","Epoch 18/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0208 - acc: 0.9934 - val_loss: 0.0017 - val_acc: 0.9994\n","Epoch 19/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0169 - acc: 0.9954 - val_loss: 6.2559e-04 - val_acc: 1.0000\n","Epoch 20/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0209 - acc: 0.9939 - val_loss: 7.3471e-04 - val_acc: 0.9997\n","Epoch 21/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0216 - acc: 0.9942 - val_loss: 0.0020 - val_acc: 0.9991\n","Epoch 22/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0135 - acc: 0.9958 - val_loss: 8.5047e-04 - val_acc: 0.9997\n","Epoch 23/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0199 - acc: 0.9940 - val_loss: 0.0016 - val_acc: 0.9991\n","Epoch 24/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0176 - acc: 0.9950 - val_loss: 0.0021 - val_acc: 0.9997\n","Epoch 25/25\n","930/930 [==============================] - 9s 10ms/step - loss: 0.0176 - acc: 0.9949 - val_loss: 0.0023 - val_acc: 0.9997\n","INFO:tensorflow:Assets written to: /content/drive/Shared drives/RAS - LIBRAS/RAS---Libras/output/treinando_rede_all.model/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2VhZIwvhKfM4","executionInfo":{"status":"ok","timestamp":1604194684422,"user_tz":180,"elapsed":1446,"user":{"displayName":"Lucas Serrano Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJg9VGUScSUQ5E1TF8bjynSe573dEKl8JptKBS3Q=s64","userId":"04398573326298672912"}},"outputId":"d84ce645-6ba3-4d9d-f6bc-683d95151350","colab":{"base_uri":"https://localhost:8080/"}},"source":["import cv2\n","import tensorflow as tf\n","\n","CATEGORIES = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"I\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"Y\"] #Possibilidades de estudo\n","\n","\n","def prepare(filepath):\n","    IMG_SIZE = 64\n","    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n","    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n","    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n","\n","\n","model = tf.keras.models.load_model(\"/content/drive/Shared drives/RAS - LIBRAS/RAS---Libras/output/treinando_rede_all.model\")\n","\n","prediction = model.predict([prepare('/content/drive/Shared drives/RAS - LIBRAS/RAS---Libras/3.png')]) # Quando usar Predict -> Deve ser uma lista\n","print(prediction)  # will be a list in a list.\n","valor = np.where(prediction==1)\n","print(CATEGORIES[int(valor[1])])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","F\n"],"name":"stdout"}]}]}